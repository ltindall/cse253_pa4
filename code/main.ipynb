{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import utils\n",
    "import my_models\n",
    "import hyperparameters as h # this prints GPU enabled = True\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files = ['sample-music.txt', 'input.txt']\n",
    "# load the inputs as a list of ints\n",
    "inputs, char2int_cypher, int2char_cypher = utils.load_music(files[1], use_custom=True)\n",
    "# full input.txt is 501470 in length\n",
    "dict_size = len(char2int_cypher) # conversion is the dict convert char to int\n",
    "\n",
    "h.char2int_cypher = char2int_cypher\n",
    "h.int2char_cypher = int2char_cypher\n",
    "\n",
    "\n",
    "# define test and validation set\n",
    "split = int(len(inputs) * h.validation_size)\n",
    "validation_set = inputs[:split]\n",
    "training_set = inputs[split:]\n",
    "\n",
    "\n",
    "# create model\n",
    "lstm = my_models.lstm_char_rnn(dict_size, h.hidden_size, h.num_hidden_layers, \n",
    "                               batch_size=h.batch_size, dropout_prob = 0.1)\n",
    "init_hidden = lstm.initialize_hidden()\n",
    "if h.GPU:\n",
    "    init_hidden = init_hidden.cuda()\n",
    "    lstm.cuda()\n",
    "\n",
    "optimizer_lstm = torch.optim.Adam(lstm.parameters(), lr=0.01)\n",
    "#optimizer_lstm = torch.optim.Adagrad(lstm.parameters(), lr=0.01)\n",
    "#optimizer_lstm = torch.optim.RMSprop(lstm.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_state, last_state = my_models.train(lstm, optimizer_lstm, h.epochs, training_set,\n",
    "                       validation_set, h.sequence_length, init_hidden, force_epochs=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_chars, hidden_activations = my_models.generate(last_state, lstm, h.temperature, \n",
    "                                                         h.prediction_length, h.till_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "map_height = int(h.prediction_length / h.map_width)\n",
    "my_models.visualize(predicted_chars, hidden_activations, \n",
    "                    map_width=h.map_width, map_height=map_height)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
