{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import utils\n",
    "import my_models\n",
    "import hyperparameters as h # this prints GPU enabled = True\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files = ['sample-music.txt', 'input.txt']\n",
    "# load the inputs as a list of ints\n",
    "inputs, char2int_cypher, int2char_cypher = utils.load_music(files[1], use_custom=True)\n",
    "# full input.txt is 501470 in length\n",
    "dict_size = len(char2int_cypher) # conversion is the dict convert char to int\n",
    "\n",
    "h.char2int_cypher = char2int_cypher\n",
    "h.int2char_cypher = int2char_cypher\n",
    "\n",
    "\n",
    "# define test and validation set\n",
    "split = int(len(inputs) * 0.1) # change 0.1 to how big we want validation set to be\n",
    "validation_set = inputs[:split]\n",
    "training_set = inputs[split:]\n",
    "\n",
    "\n",
    "# create model\n",
    "lstm = my_models.lstm_char_rnn(dict_size, h.hidden_size, h.num_hidden_layers, batch_size=h.batch_size, dropout_prob = 0.1)\n",
    "init_hidden = lstm.initialize_hidden()\n",
    "if h.GPU:\n",
    "    init_hidden = init_hidden.cuda()\n",
    "    lstm.cuda()\n",
    "\n",
    "optimizer_lstm = torch.optim.Adam(lstm.parameters(), lr=0.01)\n",
    "#optimizer_lstm = torch.optim.Adagrad(lstm.parameters(), lr=0.01)\n",
    "#optimizer_lstm = torch.optim.RMSprop(lstm.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_state, last_state = my_models.train(lstm, optimizer_lstm, h.epochs, training_set,\n",
    "                       validation_set, h.sequence_length, init_hidden, force_epochs=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_chars, hidden_activations = my_models.generate(last_state, lstm, h.temperature, h.prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "special_chars = {'\\n':'nl', ' ':'sp'}\n",
    "\n",
    "# this relies on prediction_length = 600\n",
    "for i in hidden_activations.T: \n",
    "    data = i.reshape(30,20)\n",
    "\n",
    "    plt.figure(figsize = (10,10))\n",
    "    heatmap = plt.pcolor(data,cmap='bwr')\n",
    "\n",
    "    \n",
    "    for y in range(data.shape[0]):\n",
    "        for x in range(data.shape[1]):\n",
    "            predicted_char = predicted_chars[y*20+x]\n",
    "            if predicted_char in special_chars: \n",
    "                predicted_char = special_chars[predicted_char]\n",
    "\n",
    "            plt.text(x + 0.5, y + 0.5, predicted_char,\n",
    "                horizontalalignment='center',\n",
    "                verticalalignment='center',fontsize = 12)\n",
    "    plt.colorbar(heatmap)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
