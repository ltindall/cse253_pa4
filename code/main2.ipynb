{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is enabled \n",
      "Using custom starts and ends...\n",
      "There are 95 unique characters in this dataset\n",
      "\n",
      "\n",
      "Epoch 0/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t3.254499101638794\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.893759568532308\n",
      "\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t2.4288891792297362\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.5432852109273276\n",
      "\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t2.1334501107533774\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.384935220082601\n",
      "\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.9748355150222778\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.2593013445536294\n",
      "\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.8699913660685221\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.1674521764119468\n",
      "\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.794806702931722\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.1138675212860107\n",
      "\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.7386297146479288\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.094238599141439\n",
      "\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.6961199045181274\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0601325829823813\n",
      "\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.658724013964335\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0491414070129395\n",
      "\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.6259251912434896\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0030935208002725\n",
      "\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.5976449092229208\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.013119657834371\n",
      "\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.5774212757746378\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0099674463272095\n",
      "\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.5568686564763388\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.993448257446289\n",
      "\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.5395930290222168\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.9728622833887737\n",
      "\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.5264396746953328\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.9801971912384033\n",
      "\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.5126266638437906\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.9814138412475586\n",
      "\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.5010379314422608\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.006681760152181\n",
      "\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.4893546024958293\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.9645706415176392\n",
      "\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.4790475368499756\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.9819653431574504\n",
      "\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.4722147862116495\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.970648964246114\n",
      "\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.4618611812591553\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.9879629214604695\n",
      "\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.4562246958414713\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.9858079353968303\n",
      "\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.4481191237767537\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.9855457146962483\n",
      "\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.4405056953430175\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.9805011749267578\n",
      "\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.4375515381495159\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.9894768794377644\n",
      "\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.4324100971221925\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.9814269542694092\n",
      "\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.4274761517842611\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.9964584112167358\n",
      "\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.420767879486084\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.989120602607727\n",
      "\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.4180132786432902\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.9961409171422322\n",
      "\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.413483190536499\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.9959294001261394\n",
      "\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.4106429894765218\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.9824252128601074\n",
      "\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.4060134649276734\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.015665809313456\n",
      "\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.4026793479919433\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0087831815083823\n",
      "\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3999923865000408\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.9994999170303345\n",
      "\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3961784601211549\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0099307696024575\n",
      "\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3936320463816325\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0095908641815186\n",
      "\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training with this epoch!\n",
      "training Loss:\t1.387087353070577\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0141764481862388\n",
      "\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3868759552637735\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.024794816970825\n",
      "\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3845829168955486\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t1.9982224702835083\n",
      "\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3813430547714234\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0265780289967856\n",
      "\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3796635389328002\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.009067495663961\n",
      "\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3765575170516968\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0182896852493286\n",
      "\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3746896664301553\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0376083850860596\n",
      "\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3731655756632486\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0193928480148315\n",
      "\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3703445196151733\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0408453146616616\n",
      "\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.370449177424113\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0210585594177246\n",
      "\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3656033833821615\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0344759623209634\n",
      "\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3662433783213297\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.044353723526001\n",
      "\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3646068493525187\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.030414263407389\n",
      "\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3633060455322266\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0338492393493652\n",
      "\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3615711132685344\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.053509791692098\n",
      "\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3590713421503702\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0518556038538613\n",
      "\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3598230282465618\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0422162214914956\n",
      "\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3576317469278971\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0470546881357827\n",
      "\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.356831137339274\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0360544522603354\n",
      "\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3544936259587605\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.058133840560913\n",
      "\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3532832384109497\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.065225680669149\n",
      "\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.352845549583435\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0609134833017984\n",
      "\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.352424438794454\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0470147927602134\n",
      "\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3531181732813518\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0641048749287925\n",
      "\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3522655566533406\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0440487066904702\n",
      "\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3466053406397502\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.045156558354696\n",
      "\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3469196796417235\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.042682329813639\n",
      "\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.345180614789327\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.059251387914022\n",
      "\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3464936097462972\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.049548784891764\n",
      "\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3451577266057333\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.087390104929606\n",
      "\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.346342960993449\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0566596587498984\n",
      "\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3459796905517578\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0721078713734946\n",
      "\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.34480672677358\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0757569471995034\n",
      "\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3415891170501708\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0654242833455405\n",
      "\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3433170954386393\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0571250120798745\n",
      "\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3387679735819498\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0654030640920005\n",
      "\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.339925797780355\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0655872027079263\n",
      "\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training with this epoch!\n",
      "training Loss:\t1.3369808276494344\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0631876786549888\n",
      "\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3367996613184612\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.07265035311381\n",
      "\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3369863669077555\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0693020820617676\n",
      "\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3379458665847779\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0635982354482016\n",
      "\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.335645604133606\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.061119000116984\n",
      "\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.334379760424296\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.061183134714762\n",
      "\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3338693459828694\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0600549379984536\n",
      "\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3357207218805949\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0784708658854165\n",
      "\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3349479913711548\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0763585567474365\n",
      "\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3315919001897176\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.093888759613037\n",
      "\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3326380252838135\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.068538188934326\n",
      "\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3321809927622477\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0841288566589355\n",
      "\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3310437679290772\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.080516974131266\n",
      "\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.331102681159973\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.068009694417318\n",
      "\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3304529190063477\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.063105344772339\n",
      "\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3330376386642455\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.086094935735067\n",
      "\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.328796092669169\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0833276907602944\n",
      "\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3289805094401042\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.094598372777303\n",
      "\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3306820313135783\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.081522226333618\n",
      "\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3297906955083212\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.081606467564901\n",
      "\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.329046106338501\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0948306719462075\n",
      "\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3287521600723267\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.086723725001017\n",
      "\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3287996689478556\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.1002984046936035\n",
      "\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3271519819895425\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.06486177444458\n",
      "\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3297404209772745\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0986498991648355\n",
      "\n",
      "\n",
      "Epoch 98/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.3254172563552857\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.0907273292541504\n",
      "\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "Working on sequence 0-1000000\n",
      "finished training with this epoch!\n",
      "training Loss:\t1.323592154184977\n",
      "\n",
      "Working on sequence 0-1000000\n",
      "finished validation with this epoch!\n",
      "validation Loss:\t2.07967480023702\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f54e34214e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljt/Documents/cse253_pa4/code/my_models.py:262: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  softmax_dist = torch.nn.functional.softmax(output/temperature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final output =  $\n",
      "X:10\n",
      "T:Ole2E Bowes.\n",
      "Z:id:hn-slide-93\n",
      "M:3/8\n",
      "K:D\n",
      "FDD DEF|G2G BAB|cBA ce ef|gf eg (3ed^c|1 d3 d3:|\n",
      "[2 age a2bg|fd~g2 bgab|Bc~d2 gbag|fdaB|BAB BAB ABf | e3 e3 g3 | dea ge (3fgf ||\n",
      "|:f2eg a2c2eg|fedc d2AG||\n",
      "|: ((3BcB A_Bc|dBAF E2:|\n",
      "dBed|1 c3A GABG ||\n",
      ";\n",
      "final output =  $\n",
      "XV :G2 | G4 E|G2 G2 G2 | (B2 D2 |: GB | Ac cc | de/d/ cA B>c | d2 f2 | c>c | c/2d/2/c/2 | c3 B2 cd | c>d ef/e/ | e>d/B/ B>d:|2 dd F2|B2 GB BB|A2 G2 AB|d2 f/2e/d/c/d/f/|\n",
      "ef e>c|ad ec cd|ea gf|ed dc|B>A GA:|2 GG GB|c2 cB cd/e/|f2 e/2d/2 cA GF|GA G2| DG/2 G/2F/2 | G4 :|\n",
      "V:2\n",
      "|: 2 \n",
      "B>e dB | A3 | G3 | F2G | A3 | c3- | cdc2|_ag (3efe|\n",
      "g4 g2g2 | bgf2gf | e3g (3efg fe|dcBA BA|\n",
      "d2cd g2dB|c2Bc d2ed|(3cAG ABAG FDD2:|2 BAFA D2dc|BEEB EGFA|G2E2 D2|~D3 E2g A2G|FGA GED2|\n",
      "d4 ecdB|A2e2 e2fg|fdBA B3c|:\n",
      "d2BF ABdf|geag/e/d ef/e/|dB cA|BG GB/c/|d2 d2:|\n",
      ";\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('V :G2 | G4 E|G2 G2 G2 | (B2 D2 |: GB | Ac cc | de/d/ cA B>c | d2 f2 | c>c | c/2d/2/c/2 | c3 B2 cd | c>d ef/e/ | e>d/B/ B>d:|2 dd F2|B2 GB BB|A2 G2 AB|d2 f/2e/d/c/d/f/|\\nef e>c|ad ec cd|ea gf|ed dc|B>A GA:|2 GG GB|c2 cB cd/e/|f2 e/2d/2 cA GF|GA G2| DG/2 G/2F/2 | G4 :|\\nV:2\\n|: 2 \\nB>e dB | A3 | G3 | F2G | A3 | c3- | cdc2|_ag (3efe|\\ng4 g2g2 | bgf2gf | e3g (3efg fe|dcBA BA|\\nd2cd g2dB|c2Bc d2ed|(3cAG ABAG FDD2:|2 BAFA D2dc|BEEB EGFA|G2E2 D2|~D3 E2g A2G|FGA GED2|\\nd4 ecdB|A2e2 e2fg|fdBA B3c|:\\nd2BF ABdf|geag/e/d ef/e/|dB cA|BG GB/c/|d2 d2:|\\n;',\n",
       " array([[ 0.9997922 , -0.9938025 ,  0.56719244, ..., -0.9904001 ,\n",
       "         -0.9999858 , -0.98720527],\n",
       "        [ 0.6325362 , -0.9931102 ,  0.47216928, ...,  0.9945687 ,\n",
       "          0.99899995,  0.9495709 ],\n",
       "        [ 0.6388684 , -0.9968499 ,  0.47154465, ..., -0.8407085 ,\n",
       "          0.23435535, -0.99546325],\n",
       "        ...,\n",
       "        [ 0.6695024 , -0.9999996 ,  0.9892284 , ...,  0.99652916,\n",
       "          0.9950541 , -0.00660554],\n",
       "        [ 0.11414532, -1.        , -0.8457547 , ...,  0.97021693,\n",
       "         -0.9882801 , -0.9997652 ],\n",
       "        [ 0.05660306, -1.        , -0.8393317 , ...,  0.97024065,\n",
       "         -0.9973255 , -0.99892783]], dtype=float32))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import torch\n",
    "import utils\n",
    "import my_models\n",
    "import hyperparameters as h # this prints GPU enabled = True\n",
    "\n",
    "\n",
    "files = ['sample-music.txt', 'input.txt']\n",
    "# load the inputs as a list of ints\n",
    "inputs, char2int_cypher, int2char_cypher = utils.load_music(files[1], use_custom=True)\n",
    "# full input.txt is 501470 in length\n",
    "dict_size = len(char2int_cypher) # conversion is the dict convert char to int\n",
    "\n",
    "h.char2int_cypher = char2int_cypher\n",
    "h.int2char_cypher = int2char_cypher\n",
    "\n",
    "\n",
    "# define test and validation set\n",
    "split = int(len(inputs) * h.validation_size) # change 0.1 to how big we want validation set to be\n",
    "validation_set = inputs[:split]\n",
    "training_set = inputs[split:]\n",
    "\n",
    "\n",
    "# create model\n",
    "lstm = my_models.lstm_char_rnn(dict_size, h.hidden_size, h.num_hidden_layers, batch_size=h.batch_size,dropout_prob=h.dropout,GRU=h.GRU)\n",
    "init_hidden = lstm.initialize_hidden()\n",
    "if h.GPU:\n",
    "    if h.GRU: \n",
    "        init_hidden = init_hidden.cuda()\n",
    "    else:\n",
    "        print(\"lstm working\")\n",
    "        init_hidden = (init_hidden[0].cuda(), init_hidden[1].cuda())\n",
    "    lstm.cuda()\n",
    "\n",
    "optimizer_lstm = torch.optim.Adam(lstm.parameters(), lr=0.01)\n",
    "#optimizer_lstm = torch.optim.Adagrad(lstm.parameters(), lr=0.01)\n",
    "#optimizer_lstm = torch.optim.RMSprop(lstm.parameters(), lr=0.01)\n",
    "\n",
    "mods = my_models.train(lstm, optimizer_lstm, h.epochs, training_set,\n",
    "                       validation_set, h.sequence_length, init_hidden, force_epochs=True)\n",
    "\n",
    "best_model_dict = mods[0]\n",
    "last_model_dict = mods[1]\n",
    "\n",
    "# save the best model dict to file in case we want to load it later and generate\n",
    "torch.save(best_model_dict, h.save_file)\n",
    "torch.save(last_model_dict, h.save_file_progress)\n",
    "my_models.generate(h.save_file, lstm, h.temperature, h.prediction_length, h.generate_best_file)\n",
    "my_models.generate(h.save_file_progress, lstm, h.temperature, h.prediction_length, h.generate_last_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = np.load('GRU_1lay_100unit_25seq_1000batch_100epoch_0drop_1temp.npy')\n",
    "\n",
    "plt.plot(loss[0,:],label='Train 100 units')\n",
    "\n",
    "plt.plot(loss[1,:],label='Validation 100 units')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_models.generate(h.save_file, lstm, h.temperature, h.prediction_length, h.generate_best_file)\n",
    "my_models.generate(h.save_file_progress, lstm, h.temperature, h.prediction_length, h.generate_last_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda_kernel",
   "language": "python",
   "name": "anaconda_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
